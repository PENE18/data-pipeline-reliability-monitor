# Prometheus Configuration for Data Pipeline Monitoring

global:
  scrape_interval: 15s       # Scrape metrics every 15 seconds
  evaluation_interval: 15s   # Evaluate rules every 15 seconds
  external_labels:
    cluster: 'data-pipeline'
    environment: 'local'

# Alerting configuration (optional - can add Alertmanager later)
alerting:
  alertmanagers:
    - static_configs:
        - targets: []

# Alert rules files (optional - can add alert rules)
rule_files:
  # - 'alerts.yml'

# Scrape configurations
scrape_configs:
  # Scrape Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          service: 'prometheus'

  # Scrape Pushgateway (for batch job metrics from Airflow)
  - job_name: 'pushgateway'
    honor_labels: true  # Use labels from pushed metrics
    static_configs:
      - targets: ['pushgateway:9091']
        labels:
          service: 'pushgateway'

  # Scrape StatsD Exporter (Airflow system metrics)
  - job_name: 'statsd-exporter'
    static_configs:
      - targets: ['statsd-exporter:9102']
        labels:
          service: 'airflow'

  # Optional: Add more exporters as needed
  # - job_name: 'postgres'
  #   static_configs:
  #     - targets: ['postgres-exporter:9187']